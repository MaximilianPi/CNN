---
title: "CNN"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Help Functions
```{r}
rotate = function(x) t(apply(x, 2, rev))
imgPlot = function(img, title = ""){
  col=grey.colors(255)
  image(rotate(img), col = col, xlab = "", ylab = "", axes=FALSE, main = paste0("Label: ", as.character(title)))
}

```




### Convolutional Neural Networks with Keras/Tensorflow
TensorFlow is a low level lin algebra library optimized for neural networks / machine learning. We will use the higher level API Keras. Keras uses Google's Tensorflow, Microsoft's CTNK or Theano as backend (TF as default).


[Tensorflow](https://www.tensorflow.org/)
[Keras-R](https://keras.rstudio.com/)
[Collection of Keras/Tensorflow examples in R](https://tensorflow.rstudio.com/)

[Keras-Py](https://keras.io/)
```{r}
library(keras)
```

#### Prepare Data
We will use the handwritten digits data set MNIST:
```{r}
data = dataset_mnist()
train = data$train
test = data$test

par(mfrow = c(3,3))
.n = sapply(1:9, function(x) imgPlot(train$x[x,,], train$y[x]))
```

```{r}


```



#### Build CNN
```{r}

```

In place modifications!
```{r}

```
Dropout is a regularization technique. With the probability of p, each weight will be set to zero during a training step (see [Srivastava et al., 2014](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)). Infinite number of subnetworks will be trained. For predicting, p will be set to 1. It's a type of model averaging.


Adam belongs to the class of stochastic gradient descent optimizers with adaptive learning rates (see [Kingma and Ba](http://arxiv.org/abs/1412.6980))
```{r}

```


Train model:
Epochs = How often do we fit the model on the data
batch_size = How many samples are used in one training step. 

Training in modern ANN is achieved by batch training (mini batch stochastic gradient descent). A batch of data points and not a single data point or the whole data are used for updating weights.  
```{r}

```


Evaluation on test:
```{r}


```
Ofc, CV would be better!

Task: create a second model without a fully connect layer!

```{r}



```

```{r}

```


#### Visualize Feature Maps
```{r}
K = backend()
out = K$'function'(list(model2$layers[[1]]$input, K$learning_phase()),
                   list(model2$layers[[1]]$output))
imgPlot(out(list(train_x[1,,,,drop = FALSE], 0))[[1]][1,,,1],
        which.max(train_y[1,]))



```

